{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXHEqRjEzExB"
      },
      "source": [
        "# **ANÁLISIS DEL ESTADO Y EVOLUCIÓN DE LOS EMBALSES DE AGUA NACIONALES**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuSIBbMbzm5L"
      },
      "source": [
        "Este notebook explica el trabajo de preprocesamiento y preparación de los datos para implementar una serie de visualizaciónes que expliquen el estado y la evolución temporal de la reserva hídrica del país para los embalses con capacidad superior a 5hm3.\n",
        "\n",
        "Para llevar a cabo esta tarea de manera práctica hemos escogido conjuntos de datos que contienen información relevante sobre los embalses a largo de los últimos años. A partir de estos datos observaremos las características principales y las comparativas en sus evoluciones.\n",
        "\n",
        "Pero antes tenemos que realizar una serie de tareas para preparar los datos que posteriormente utilizaremos. A continuación, te explicamos cómo lo hacemos.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWxD9_583Jb6"
      },
      "source": [
        "# Pasos que se seguirán para preparar los datos\n",
        "1. Importación de librerias\n",
        "2. Carga de archivos de datos a utilizar\n",
        "3. Modificación y ajuste de las variables\n",
        "4. Detención y tratamiento de datos ausentes(NAs)\n",
        "5. Generación de nuevas variables \n",
        "6. Creación de tabla para visualización \"Evolución histórica de la reserva hídrica entre los años 2012 y 2022\"\n",
        "7. Creación de tabla para visualización \"Reserva hídrica (hm3) entre los años 2012 y 2022\"\n",
        "8. Creación de tabla para visualización \"Reserva hídrica (%) entre los años 2012 y 2022\"\n",
        "9. Creación de tabla para visualización \"Evolución mensual de la reserva hídrica (hm3)\"\n",
        "10. Guardado de las tablas con los datos preprocesados\n",
        "\n",
        "Una vez que has iniciado sesión con tu cuenta Gmail, podrás ejecutar cada script o celda de código. Tan solo debes hacer click en el símbolo de la esquina superior izquierda de cada celda con código. El resultado de la ejecución aparecera justo debajo de cada script.\n",
        "\n",
        "También puedes ejecutar todos los scripts pulsando Ctrl+F9 o eligiendo en el menú superior la opción \"Entorno de ejecución\" y seleccionando \"Ejecutar todas\".\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1sEcS8FZnqZ"
      },
      "source": [
        "## 1. Importación de librerias\n",
        "Lo primero que debemos hacer es instalar y cargar las librerías para el preprocesamiento de los datos. Existen una gran cantidad de librerías disponibles en Python, pero una de las más populares y adecuadas para trabajar con conjuntos de datos es la librería **Pandas**.\n",
        "\n",
        "*    [Pandas](https://pandas.pydata.org/) es una librería de Python especializada en el manejo y análisis de estructuras de datos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "b78JNY2_1-Py"
      },
      "outputs": [],
      "source": [
        "# Importamos las librerías a utilizar\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBvsEI0n3Wcx"
      },
      "source": [
        "## 2. Carga de datos\n",
        "\n",
        "Cargamos los conjuntos de datos para explorarlos y realizar algunas tareas básicas de limpieza y procesado de datos.\n",
        "\n",
        "Los conjuntos de datos con los cuales vamos a trabajar, se encuentran almacenados en el repositorio del **[Laboratorio de datos](https://github.com/datosgobes/Laboratorio-de-Datos/tree/main/Visualizaciones/Estudio%20estado%20de%20los%20embalses%20nacionales/Datasets%20originales)** de GitHub de datos.gob.es, desde donde pueden ser descargados o cargados directamente como es el caso. \n",
        "\n",
        "*   Para la carga de los datos recurriremos a la función [.read_excel()](https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html), donde le indicaremos la ruta del dataset dentro del repositorio de Github.\n",
        "\n",
        "*   Para visualizar la información principal del dataset cargado utilizamos la función [.info()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QH_QWctm3ZRk"
      },
      "outputs": [],
      "source": [
        "# Cargamos desde Github el dataset que contiene la información de los datos históricos de la reserva hídrica \n",
        "url = \"https://github.com/Admindatosgobes/Laboratorio-de-Datos/blob/b5e65d268f88323b95b98d04e1a24a6d87ce53c6/Visualizaciones/Estado%20embalses%20nacionales/Datasets%20originales/Datos%20embalses.xlsx?raw=true\"\n",
        "embalses = pd.read_excel(url)\n",
        "\n",
        "# Visualizamos la información principal del dataset de datos históricos\n",
        "embalses.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69yoSvTMOudb"
      },
      "source": [
        "Observamos la **principal información del dataset \"embalses\"**, donde se muestra el nombre, número, tipo y cantidad de datos de cada variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqntxoHiE_8j"
      },
      "outputs": [],
      "source": [
        "# Cargamos desde Github el dataset que contiene la información con datos geográficos \n",
        "url = \"https://github.com/Admindatosgobes/Laboratorio-de-Datos/blob/da405383c5fae3811ecb0dbc72baa4060ae218cf/Visualizaciones/Estado%20embalses%20nacionales/Datasets%20originales/Embalses_enriquecido.xlsx?raw=true\"\n",
        "embalses_geo = pd.read_excel(url)\n",
        "\n",
        "# Visualizamos la información principal del dataset de datos geográficos\n",
        "embalses_geo.info()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCWZx9jbLNbd"
      },
      "source": [
        "Observamos la **principal información del dataset \"embalses_geo\"**, donde se muestra el nombre, número, tipo y cantidad de datos de cada variable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSaj9zvDWEuh"
      },
      "source": [
        "## 3. Modificación y ajuste de las variables \n",
        "\n",
        "Una de las primeras acciones que hay que realizar tras la carga de los datos, es verificar las variables y **modificarlas buscando que se adecuen a nuestras tablas de trabajo**. En este caso, renombraremos , modificaremos el tipo , eliminaremos las que no nos interesan para el análisis y sustituiremos los valores decimales con coma por punto.\n",
        "\n",
        "*   Para renombrar las variables utilizamos la función [.rename()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html)\n",
        "\n",
        "\n",
        "*   Para convertir el nombre de una variable a letras minúsculas utilizamos la función [.str.lower()](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.lower.html?)\n",
        "\n",
        "*   Para sustituir los valores decimales con coma por punto utilizamos la función [.str.replace()](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.replace.html?)\n",
        "\n",
        "*   Para modificar el tipo de variable utilizamos la función [.astype()](https://pandas.pydata.org/docs/reference/api/pandas.Series.astype.html?)\n",
        "\n",
        "*    Para modificar el tipo de variable a una fecha utilizamos la función [.to_datetime()](https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html)\n",
        "\n",
        "*   Para eliminar una variable utilizamos la función [.drop()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1LXtAXNUAa8"
      },
      "source": [
        "Para el dataset **\"embalses\"** realizamos los siguientes pasos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAXtcZzVWEHA"
      },
      "outputs": [],
      "source": [
        "# Renombramos las variables\n",
        "embalses = embalses.rename(columns= {\"AMBITO_NOMBRE\": \"demarcacion_hidrografica\", \"AGUA_TOTAL\": \"capacidad_total\", \"AGUA_ACTUAL\": \"volumen_actual\"})\n",
        "\n",
        "# Modificamos el nombre de los encabezados a letras minúsculas\n",
        "embalses= embalses.rename(columns=str.lower)\n",
        "\n",
        "# Sustituimos los valores decimales con coma por punto\n",
        "embalses[\"capacidad_total\"] = embalses[\"capacidad_total\"].str.replace(\",\",\".\")\n",
        "embalses[\"volumen_actual\"] = embalses[\"volumen_actual\"].str.replace(\",\",\".\")\n",
        "\n",
        "# Transformamos el tipo de variable a floats\n",
        "embalses[\"capacidad_total\"]= embalses[\"capacidad_total\"].astype(float)\n",
        "embalses[\"volumen_actual\"] = embalses[\"volumen_actual\"].astype(float)\n",
        "\n",
        "# Transformamos el tipo de variable a fecha dandole el formato deseado\n",
        "embalses[\"fecha\"] = pd.to_datetime(embalses[\"fecha\"], format = \"%d/%m/%Y\")\n",
        "\n",
        "# Eliminamos las columnas que contienen variables que no interesan para el análisis\n",
        "embalses = embalses.drop(axis=1, columns= [\"electrico_flag\"])\n",
        "embalses.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SY8mEdeOUBk7"
      },
      "source": [
        "Visualizamos las 5 primeras filas del dataset para comprobar que las **modificaciónes y ajustes** de las variables se ha realizado correctamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNeXkO5GFpdt"
      },
      "source": [
        "Para el sataset **\"embalses_geo\"** realizamos los siguientes pasos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUSV60R2FdHJ"
      },
      "outputs": [],
      "source": [
        "# Filtramos las variables que nos interesan para el análisis\n",
        "embalses_geo = embalses_geo[[\"X\",\"Y\",\"NOMBRE\",\"DEMARC\",\"CAUCE\",\"Google\",\"OpenStreetMap\",\"Wikidata\", \"image\",\"Imagen\", \"USO\", \"PROVINCIA\"]]\n",
        "\n",
        "# Renombramos las variables\n",
        "embalses_geo = embalses_geo.rename(columns= {\"DEMARC\": \"demarcación_hidrografica\",\"NOMBRE\":\"embalse_nombre\"})\n",
        "\n",
        "# Modificamos el nombre de los encabezados a letras minúsculas\n",
        "embalses_geo= embalses_geo.rename(columns=str.lower)\n",
        "embalses_geo.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cijcjaZwUh-9"
      },
      "source": [
        "Visualizamos las 5 primeras filas del dataset para comprobar que las **modificaciónes y ajustes** de las variables se ha realizado correctamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTwy42eMNd-Y"
      },
      "source": [
        "## 4. Detención y tratamiento de datos ausentes (NAs)\n",
        "\n",
        "La presencia de datos ausentes es una **problemática habitual** en muchos conjuntos de datos. Tratar con conjuntos de datos en los que existan puede generar problemas durante los posteriores análisis.\n",
        "\n",
        "\n",
        "*   Para buscar los datos ausentes en cada variable utilizamos la función [is.null()](https://pandas.pydata.org/docs/reference/api/pandas.isnull.html?)\n",
        "\n",
        "*   Para eliminar los datos ausentes en el dataset utilizamos la función [.drop.na()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKv72K34Vyjx"
      },
      "source": [
        "Para el dataset **\"embalses\"** realizamos los siguientes pasos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ea9NGqiOs-AU"
      },
      "outputs": [],
      "source": [
        "# Búsqueda de datos ausentes.\n",
        "embalses.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBBbKHW6fReA"
      },
      "source": [
        "Obtenemos la **suma de valores nulos por variable**. En este caso observamos que dentro del dataset hay 2 valores nulos en la columna \"capacidad_total\" y otros 2 en la columna \"volumen_actual\". Debido a que el conjunto de datos es lo suficientemente grande y no se pierde información relevante al **eliminar** esas filas, procedemos a eliminarlas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jAX5NMINZWFs"
      },
      "outputs": [],
      "source": [
        "# Eliminamos las filas con valores ausentes\n",
        "embalses = embalses.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVqRqL81WLg0"
      },
      "source": [
        "Para el dataset **\"embalses_geo\"** realizamos los siguientes pasos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igP2vqT6HHC8"
      },
      "outputs": [],
      "source": [
        "# Búsqueda de datos ausentes\n",
        "embalses_geo.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttpK6vf4WRHU"
      },
      "source": [
        "Obtenemos la suma de valores nulos por variable. En este caso observamos que dentro del dataset hay **grandes cantidades** de valores nulos en las columnas \"google\", \"openstreetmap\" y \"wikidata\". En esta ocasión **no se eliminan** las filas que presentan valores nulos ya que significaría una pérdida importante de la información."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahgjmOPhYEs9"
      },
      "source": [
        "## 5. Generación de nuevas variables\n",
        "\n",
        "Una acción muy común en el análisis de datos, es la creación de nuevas variables a partir de las variables existentes en los datos, ya que en ocasiones interesa **trabajar con datos calculados**, en lugar de los datos de origen.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcU_jmDQXFYK"
      },
      "source": [
        "Para el dataset **\"embalses\"** realizamos los siguientes pasos:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AN3eKmDnXgKd"
      },
      "source": [
        "Creamos la variable **\"porcentaje_actual\"** dentro de \n",
        "una nueva columna con el valor del porcentaje de agua embalsado en cada momento sobre la capacidad total (porcentaje de llenado). Para ello se utilizan los datos de las variables \"volumen_actual\" y \"capacidad_total\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8VsCtWgYKWq"
      },
      "outputs": [],
      "source": [
        "# Generamos una nueva variable con el porcentaje de llenado del ambalse\n",
        "embalses[\"porcentaje_actual\"] = round(100*(embalses[\"volumen_actual\"]/embalses[\"capacidad_total\"]), 2)\n",
        "embalses.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pl1gg4S3oPt-"
      },
      "source": [
        "Visualizamos las 5 primeras filas del dataset para comprobar que la **nueva variable \"porcentaje_actual\"** ha sido creada correctamente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwT0qxA4Yaoh"
      },
      "source": [
        "Dividimos la variable fecha en **dos nuevas variables** correspondientes a dos columnas, una con el año y la otra con el mes.\n",
        "\n",
        "*   Para obtener el valor del año y del mes de la variable fecha utilizamos las funciones [.dt.year](https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.year.html) y [.dt.month](https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.month.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjVAPvSFYa5R"
      },
      "outputs": [],
      "source": [
        "# Generamos dos nuevas columnas a partir de la columna \"fecha\". Una con el año y la otra con el mes\n",
        "embalses[\"mes\"] = embalses[\"fecha\"].dt.month\n",
        "embalses[\"año\"] = embalses[\"fecha\"].dt.year\n",
        "embalses.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6t_RlGZosKU"
      },
      "source": [
        "Visualizamos las 5 primeras filas del dataset para comprobar que las **nuevas variables \"mes\" y \"año\"** han sido creadas correctamente.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeDUKGr0YCI-"
      },
      "source": [
        "Para el dataset **\"embalses_geo\"** realizamos los siguientes pasos:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0mLsgfoYNy2"
      },
      "source": [
        "Creeamos la varible \"**coordenadas**\" uniendo las variables \"x\" e \"y\" y sustituimos caracteres que no son procesables por herramientas de visualización en las variables **\"uso\"** y **\"provincia\"**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W48sP6cKHvw9"
      },
      "outputs": [],
      "source": [
        "# Generamos una nueva variable con las coordenadas X e Y juntas\n",
        "embalses_geo[\"coordenadas\"] = embalses_geo['x'].astype(str)+\",\"+embalses_geo['y'].astype(str)\n",
        "\n",
        "# Sustituimos caracterres no procesables por herramientas de visualización\n",
        "embalses_geo[\"uso\"] = embalses_geo[\"uso\"].str.replace(\"\\n\", \",\")\n",
        "embalses_geo[\"provincia\"] = embalses_geo[\"provincia\"].str.replace(\"/\", \",\")\n",
        "embalses_geo.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xCoaHNmXvoH"
      },
      "source": [
        "Una vez hemos realizado el tratamiento previo de los datos desarrollado hasta ahora, pasamos a crear las **tablas de datos** para alimentar a la herramienta de visualización."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfBA-fb5FoZw"
      },
      "source": [
        "## 6. Creación de tabla para visualización \"Evolución histórica de la reserva hídrica entre los años 2012 y 2022\"\n",
        "Generamos la primera tabla de datos preparada para alimentar la herramienta de visualización que vamos a utilizar, Google Data Studio.\n",
        "\n",
        "Para ello **filtramos** el dataset para obtener los datos entre el **01/01/2012 y el 01/01/2022**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1K9jeK3KJUnM"
      },
      "outputs": [],
      "source": [
        "# Filtramos el dataset para quedarnos con los valores históricos del 2012 al 2022\n",
        "tabla_lin = embalses[(embalses[\"fecha\"]>\"01/01/2012\") & (embalses[\"fecha\"]<\"01/01/2022\")]\n",
        "tabla_lin.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-G5WP4Q3Ji5i"
      },
      "source": [
        "Visualizamos las 5 primeras filas de la tabla y comprobamos que se ha **filtrado** correctamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsWcz4LQ16dj"
      },
      "source": [
        "## 7. Creación de tabla para visualización \"Reserva hídrica (hm3) entre los años 2012 y 2022\"\n",
        "\n",
        "Generamos **una nueva tabla de datos** preparada para alimentar la herramienta de visualización que vamos a utilizar, Google Data Studio.\n",
        "\n",
        "Para ello partimos del **dataset filtrado** en el apartado anterior. **Agrupamos** las variables por embalse, **calculamos la media** de los registros del volumen de agua y **renombramos** la nueva variable.\n",
        "\n",
        "\n",
        "*   Para agrupar las varibles utilizamos la función [.groupby()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html)\n",
        "\n",
        "*   Para renombrar las variables utilizamos las funciones [.rename()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qG8NYE_t5hrW"
      },
      "outputs": [],
      "source": [
        "# Agrupamos el dataset por nombre del embalse y generamos una columna con la media del volumen\n",
        "tabla_vol = round(tabla_lin.groupby([\"demarcacion_hidrografica\", \"embalse_nombre\"])[\"volumen_actual\"].mean().reset_index(),2)\n",
        "\n",
        "# Renombramos la nueva columna generada\n",
        "tabla_vol = tabla_vol.rename(columns= {\"volumen_actual\": \"volumen_medio_10\"})\n",
        "tabla_vol.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lumwtt_g2vPY"
      },
      "source": [
        "Una vez generada la tabla **\"tabla_vol\"** la visualizamos para comprobar que los datos son correctos. En este caso se comprueba que se ha calculado el valor medio de volumen de agua por embalse y ha sido almacenada en una nueva variable \"**\"volumen_medio_10\"**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNhGEDLE1JOp"
      },
      "source": [
        "## 8. Creación de tabla para visualización \"Reserva hídrica (%) entre los años 2012 y 2022\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MYHVdimoxHb"
      },
      "source": [
        "Generamos una **nueva tabla de datos** preparada para alimentar la herramienta de visualización que vamos a utilizar, Google Data Studio.\n",
        "\n",
        "Para ello partimos del **dataset filtrado** en el apartado anterior. **Agrupamos** las variables por embalse, **calculamos la media** de los registros del porcentaje de llenado y **renombramos** la nueva variable.\n",
        "\n",
        "\n",
        "*   Para agrupar las varibles utilizamos la función [.groupby()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html)\n",
        "\n",
        "*   Para renombrar las variables utilizamos las funciones [.rename()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ciG0LDOX2axa"
      },
      "outputs": [],
      "source": [
        "# Agrupamos el dataset por nombre del embalse y generamos una columna con la media del porcentaje\n",
        "tabla_por = round(tabla_lin.groupby([\"demarcacion_hidrografica\", \"embalse_nombre\"])[\"porcentaje_actual\"].mean().reset_index(),2)\n",
        "\n",
        "# Renombramos la nueva columna generada\n",
        "tabla_por = tabla_por.rename(columns= {\"porcentaje_actual\": \"porcentaje_medio_10\"})\n",
        "tabla_por.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OuTSrX65DHM"
      },
      "source": [
        "Una vez generada la tabla **\"tabla_por\"** la visualizamos para comprobar que los datos son correctos. En este caso se comprueba que ha sido calculado el valor medio de porcentaje de llenado por embalse y ha sido almacenado en una nueva variable \"**\"porcentaje_medio_10\"**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEkubFARRTYf"
      },
      "source": [
        "## 9. Creación de tabla para visualización \"Evolución mensual de la reserva hídrica (hm3)\"\n",
        "\n",
        "Generamos una **nueva tabla de datos** preparada para alimentar la herramienta de visualización que vamos a utilizar, **Google Data Studio**.\n",
        "\n",
        "Esta tabla contiene los datos medios de volumen de agua embalsada por mes para distintas series temporales. Esta series temporales corresponden a los años **2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020 y 2021**.\n",
        "\n",
        "Para ello partimos del **dataset filtrado en el apartado 5** con los datos pertenecientes al periodo temporal entre el 01/01/2012 y el 01/01/2022. Una vez filtrado, **agrupamos** las variables por embalse y mes, **calculamos la media** de los registros del volumen de agua y **renombramos** la nueva variable.\n",
        "\n",
        "\n",
        "*   Para agrupar las varibles utilizamos la función [groupby()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html)\n",
        "\n",
        "*   Para renombrar las variables utilizamos la funciones [.rename()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html)\n",
        "\n",
        "*   Para unir las tablas en utilizamos la función [.merge()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uuJU2lk6yKI"
      },
      "outputs": [],
      "source": [
        "# Creamos una lista con las fechas iniciales y finales de las series temporales\n",
        "lista = [\"01/01/2012\", \"01/01/2013\", \"01/01/2014\", \"01/01/2015\", \"01/01/2016\", \"01/01/2017\", \"01/01/2018\", \"01/01/2019\", \"01/01/2020\", \"01/01/2021\", \"01/01/2022\"]\n",
        "\n",
        "# Creamos un bucle que recorra la lista anterior\n",
        "for i in range(len(lista)-1):\n",
        "    # Filtramos el dataset con los datos correspondientes a cada una de las series temporales\n",
        "    tabla_mini = tabla_lin[(embalses[\"fecha\"] > lista[i]) & (embalses[\"fecha\"]<lista[i+1])]\n",
        "    # Agrupamos el dataset por demarcación hidrográfica, nombre del embalse y mes. Generamos una columna con la media del volumen\n",
        "    lin = tabla_mini.groupby([\"demarcacion_hidrografica\",\"embalse_nombre\", \"mes\"])[\"volumen_actual\"].mean().reset_index()\n",
        "    # Renombramos la nueva columna generada con el valor medio\n",
        "    lin = lin.rename(columns= {\"volumen_actual\": lista[i].split(\"/\")[2]})\n",
        "\n",
        "    # Unificamos los datos de las distintas series temporales en una misma tabla\n",
        "    if i == 0:\n",
        "      tabla_lin_mes = lin\n",
        "    else:\n",
        "      tabla_lin_mes = tabla_lin_mes.merge(lin, on=[\"demarcacion_hidrografica\",\"embalse_nombre\",\"mes\"], how = \"inner\")\n",
        "\n",
        "tabla_lin_mes.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OByVfD97GqF"
      },
      "source": [
        "Una vez generada la tabla **\"tabla_lin_mes\"** la visualizamos para comprobar que los datos son correctos. En este caso se comprueba que los datos del \"volumen_actual\" han sido agrupados por **mes** y en las **distintas series temporales** previamente especificadas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKe2E_R3nIP1"
      },
      "source": [
        "## 10. Guardado de las tablas para la generación de la visualización.\n",
        "\n",
        "Una vez que tenemos las tablas con la estructura y variables que nos interesan para realizar la visualización de los datos, lo guardaremos como archivo de datos en formato **CSV** para posteriormente realizar otros análisis estadísticos o utilizarlo en otras herramientas de visualización de datos como la que abordamos a continuación. Es importante guardarlo con una codificación **UTF-8** (Formato de Transformación Unicode) para que los caracteres especiales sean identificados de manera correcta por cualquier software.\n",
        "\n",
        "*   Para guardar las tablas como archivos CSV utilizamos la función [.to_csv()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "oCWv-S6AscQE"
      },
      "outputs": [],
      "source": [
        "# Guardamos las tablas como archivos csv.\n",
        "tabla_lin.to_csv(\"lineas.csv\", index = False, encoding = \"utf-8\")\n",
        "tabla_vol.to_csv(\"volumen.csv\", index = False, encoding = \"utf-8\")\n",
        "tabla_por.to_csv(\"porcentaje.csv\", index = False, encoding = \"utf-8\")\n",
        "tabla_lin_mes.to_csv(\"lineas_mensual.csv\", index = False, encoding = \"utf-8\")\n",
        "embalses_geo.to_csv(\"geo.csv\", index = False, encoding = \"utf-8\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQXL49kOqJjW"
      },
      "source": [
        "Una vez generados los archivos, en el menú desplegable de la izquierda de esta pantalla, en la sección \"Archivos\" (el icono de la carpeta), encontraremos los archivos que acabamos de guardar dentro de la carpeta \"sample_data\". Usando el menú contextual, los ficheros pueden ser descargados.\n",
        "\n",
        "No obstante, dispones de estos conjuntos de datos preprocesados en esta carpeta del Laboratorio de datos del GitHub de datos.gob.es.\n",
        "\n",
        "A contintuación, puedes seguir los siguientes pasos para visualizar los datos que acabamos de preprocesar utilizando la herramienta Google Data Studio en el post *(añadir nombre y enlace al post)*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Análisis del estado y evolución de los embalses de agua nacionales.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}